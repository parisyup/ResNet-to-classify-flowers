{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhMxuo14VzV9"
   },
   "source": [
    "I have chosen the ResNet model. Because the ResNet model can train extremely deep networks efficiently and without experiencing the vanishing gradient problem. It can acquire intricate and abstract representations of the input data thanks to the usage of residual connections, which enhances performance on picture classification tasks. Its architecture is incredibly versatile and adaptable to our purpose. Cross-entropy loss is a popular and the best option for this situation in the context of image classification since it is an appropriate loss function for multi-class classification problems. Cross-entropy loss has the mathematical qualities that make it simple to compute gradients and guarantee that the gradient will always be positive. which is the best for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {
    "id": "M9sn7w2C_LmD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "id": "mWqBuUqs_MTL"
   },
   "outputs": [],
   "source": [
    "path = 'symbols_dataset' #or the path to the folder with the data set for question 3 without the redundant data (.Mac and the other one)\n",
    "t_tfms = tt.Compose([tt.Grayscale(num_output_channels=1), tt.RandomHorizontalFlip(), tt.ToTensor()])\n",
    "dataset = ImageFolder(path, transform=t_tfms)\n",
    "\n",
    "tr_size = int(0.9 * len(dataset))\n",
    "t_size = len(dataset) - tr_size\n",
    "tr_data, t_data = random_split(dataset, [tr_size, t_size])\n",
    "t_dl = DataLoader(tr_data, batch_size=100, shuffle=True, num_workers=2, pin_memory=True)\n",
    "v_dl = DataLoader(t_data, batch_size=100, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "id": "vNEa0c51_RDU"
   },
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "        \n",
    "def swapDevice(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [swapDevice(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {
    "id": "Ge6lP6fg_Tx2"
   },
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl: \n",
    "            yield swapDevice(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {
    "id": "D3AIOgF4_WGz"
   },
   "outputs": [],
   "source": [
    "t_dl = DeviceDataLoader(t_dl, get_device())\n",
    "v_dl = DeviceDataLoader(v_dl, get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {
    "id": "ibX0evlY_YkP"
   },
   "outputs": [],
   "source": [
    "def accuracy(ops, lab):\n",
    "    _, preds = torch.max(ops, dim=1)\n",
    "    output = torch.tensor(torch.sum(preds == lab).item() / len(preds))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "id": "e7rIKWtk_aGA"
   },
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, b):\n",
    "        imgs, labels = b\n",
    "        out = self(imgs)                  \n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, b):\n",
    "        imgs, labels = b \n",
    "        out = self(imgs)                    \n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        acc = accuracy(out, labels)           \n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, ops):\n",
    "        b_l = [x['val_loss'] for x in ops]\n",
    "        e_loss = torch.stack(b_l).mean()   \n",
    "        b_accs = [x['val_acc'] for x in ops]\n",
    "        e_acc = torch.stack(b_accs).mean()      \n",
    "        return {'val_loss': e_loss.item(), 'val_acc': e_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, e, result):\n",
    "        print(\"E# [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(e, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {
    "id": "Bu7dHNh2_b8O"
   },
   "outputs": [],
   "source": [
    "def conv(in_c, out_c, pool=False):\n",
    "    l = [nn.Conv2d(in_c, out_c, kernel_size=3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True)]\n",
    "    if pool: l.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {
    "id": "Y_mhpa3J_eiT"
   },
   "outputs": [],
   "source": [
    "class ResNet9(ImageClassificationBase):           \n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "          \n",
    "        self.conv1 = conv(in_channels, 96, pool=True)\n",
    "        self.conv2 = conv(96, 192, pool=True)\n",
    "        self.res1 = nn.Sequential(conv(192, 192), conv(192, 192))\n",
    "        self.conv4 = conv(192, 384, pool=True)\n",
    "        self.res2 = nn.Sequential(conv(384, 384), conv(384, 384))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), nn.Flatten(), nn.Linear(384, num_classes))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {
    "id": "bS5donxi_f1h"
   },
   "outputs": [],
   "source": [
    "model = swapDevice(ResNet9(1, 5), get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {
    "id": "Pw_XsaLm_g6w"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(m, val_l):\n",
    "    m.eval()\n",
    "    outputs = [m.validation_step(batch) for batch in val_l]\n",
    "    return m.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {
    "id": "OQAr33uA_h8z"
   },
   "outputs": [],
   "source": [
    "def foc(n_of_es, lr, m, train_l, val_l, w_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    h = []\n",
    "\n",
    "    opt = opt_func(m.parameters(), lr, weight_decay=w_decay)\n",
    "    sc = torch.optim.lr_scheduler.OneCycleLR(opt, lr, epochs=n_of_es,  steps_per_epoch=len(train_l))\n",
    "    \n",
    "    for epoch in range(n_of_es):\n",
    "        m.train()\n",
    "        ls = []\n",
    "        lrs = []\n",
    "        for batch in train_l:\n",
    "            loss = m.training_step(batch)\n",
    "            ls.append(loss)\n",
    "            loss.backward()\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(m.parameters(), grad_clip)    \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            lrs.append(get_lr(opt))\n",
    "            sc.step()\n",
    "\n",
    "        r = evaluate(m, val_l)\n",
    "        r['train_loss'] = torch.stack(ls).mean().item()\n",
    "        r['lrs'] = lrs\n",
    "        m.epoch_end(epoch, r)\n",
    "        h.append(r)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {
    "id": "VPCETact_jdZ"
   },
   "outputs": [],
   "source": [
    "opt_func = torch.optim.Adam\n",
    "weight_decay = 1e-3\n",
    "n_o_epochs = 5\n",
    "m_lr = 1.1e-6\n",
    "grad_clip = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vljXFZL0_klO",
    "outputId": "226076d0-92e0-41ed-cb60-97d029f9e36b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E# [0], train_loss: 2.6246, val_loss: 1.9487, val_acc: 0.3936\n",
      "E# [1], train_loss: 1.1289, val_loss: 0.5547, val_acc: 0.8603\n",
      "E# [2], train_loss: 0.4310, val_loss: 0.3390, val_acc: 0.9372\n",
      "E# [3], train_loss: 0.3053, val_loss: 0.2792, val_acc: 0.9455\n",
      "E# [4], train_loss: 0.2773, val_loss: 0.2670, val_acc: 0.9522\n"
     ]
    }
   ],
   "source": [
    "h = [evaluate(model, v_dl)]\n",
    "h += foc(n_o_epochs, m_lr, model, t_dl, v_dl, grad_clip=grad_clip, w_decay=weight_decay, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {
    "id": "7afBuYbw_03A"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights.pkl')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
